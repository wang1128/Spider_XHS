import requests
import time
import json


def test_user_crawler_with_status(
        user_url: str,
        save_choice: str = "all",
        min_likes: int = 100,
        timeout: int = 300,
        server_port: int = 8080
):
    """å‚æ•°åŒ–çš„ç”¨æˆ·çˆ¬è™«æµ‹è¯•"""
    payload = {
        "user_url": user_url,
        "save_choice": save_choice,
        "min_likes": min_likes
    }

    try:
        response = requests.post(
            f"http://localhost:{server_port}/api/crawl_user",
            json=payload,
            timeout=10
        )
        response.raise_for_status()
    except requests.exceptions.RequestException as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {str(e)}")
        if hasattr(e, 'response'):
            print(f"æœåŠ¡å™¨å“åº”: {e.response.text}")
        return None

    task_info = response.json()
    print(f"\n=== ç”¨æˆ·çˆ¬è™«æµ‹è¯•å¯åŠ¨ ===")
    print(f"ç”¨æˆ·URL: {user_url}")
    print(f"ä»»åŠ¡ID: {task_info['task_id']}")

    start_time = time.time()
    while time.time() - start_time < timeout:
        try:
            status_res = requests.get(
                f"http://localhost:{server_port}{task_info['status_url']}",
                timeout=5
            )
            status = status_res.json()

            status_msg = (
                f"\r[è¿›åº¦ {status.get('progress', 0)}%] "
                f"æˆåŠŸ: {status.get('success', 0)} "
                f"å¤±è´¥: {status.get('failed', 0)} "
                f"å½“å‰å¤„ç†: {status.get('current_url', 'æ— ')}"
            )
            print(status_msg.ljust(100), end="")

            if status["status"] in ["completed", "failed"]:
                break

            time.sleep(2)
        except requests.exceptions.RequestException as e:
            print(f"\nâš ï¸ çŠ¶æ€æŸ¥è¯¢å¼‚å¸¸: {str(e)}")
            time.sleep(5)
    # else:
    #     print("\nâŒ› ä»»åŠ¡è¶…æ—¶")
    #     return None

    print("\n\n=== æœ€ç»ˆçŠ¶æ€ ===")
    print(json.dumps(status, indent=2, ensure_ascii=False))
    return status


def test_search_with_status(
        query: str,
        require_num: int = 20,
        save_choice: str = "all",
        min_likes: int = 100,
        sort: str = "general",
        note_type: int = 0,
        timeout: int = 300,
        server_port: int = 8080
):
    """å‚æ•°åŒ–çš„æœç´¢æµ‹è¯•ï¼ˆæ”¯æŒç¬”è®°ç±»å‹ï¼‰"""
    if note_type not in [0, 1, 2]:
        raise ValueError("æ— æ•ˆç¬”è®°ç±»å‹ï¼š0-å…¨éƒ¨ 1-è§†é¢‘ 2-å›¾æ–‡")

    payload = {
        "query": query,
        "require_num": require_num,
        "save_choice": save_choice,
        "min_likes": min_likes,
        "sort": sort,
        "note_type": note_type
    }

    try:
        response = requests.post(
            f"http://localhost:{server_port}/api/crawl_search",
            json=payload,
            timeout=10
        )
        response.raise_for_status()
    except requests.exceptions.RequestException as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {str(e)}")
        if hasattr(e, 'response'):
            print(f"æœåŠ¡å™¨å“åº”: {e.response.text}")
        return None

    task_info = response.json()
    print(f"\n=== æœç´¢æµ‹è¯•å¯åŠ¨ ===")
    print(f"æœç´¢è¯: {query}")
    print(f"ç¬”è®°ç±»å‹: {['å…¨éƒ¨', 'è§†é¢‘', 'å›¾æ–‡'][note_type]}")
    print(f"ä»»åŠ¡ID: {task_info['task_id']}")

    start_time = time.time()
    while time.time() - start_time < timeout:
        try:
            status_res = requests.get(
                f"http://localhost:{server_port}{task_info['status_url']}",
                timeout=5
            )
            status = status_res.json()

            status_msg = (
                f"\r[è¿›åº¦ {status.get('progress', 0)}%] "
                f"æˆåŠŸ: {status.get('success', 0)} "
                f"å¤±è´¥: {status.get('failed', 0)} "
                f"å½“å‰å¤„ç†: {status.get('current_url', 'æ— ')}"
            )
            print(status_msg.ljust(100), end="")

            if status["status"] in ["completed", "failed"]:
                break

            time.sleep(2)
        except requests.exceptions.RequestException as e:
            print(f"\nâš ï¸ çŠ¶æ€æŸ¥è¯¢å¼‚å¸¸: {str(e)}")
            time.sleep(5)
    # else:
    #     print("\nâŒ› ä»»åŠ¡è¶…æ—¶")
    #     return None

    print("\n\n=== æœ€ç»ˆçŠ¶æ€ ===")
    print(json.dumps(status, indent=2, ensure_ascii=False))

    # éªŒè¯ç¬”è®°ç±»å‹
    if status["status"] == "completed":
        actual_types = set()
        for item in status.get("details", []):
            if item.get("type"):
                actual_types.add(item["type"])
        print(f"\néªŒè¯ç»“æœ: å®é™…è·å–çš„ç¬”è®°ç±»å‹ - {', '.join(actual_types) or 'æ— '}")

    return status


if __name__ == "__main__":
    # ç”¨æˆ·æµ‹è¯•ç¤ºä¾‹
    user_test_params = {
        "user_url": "https://www.xiaohongshu.com/user/profile/63fec5ff000000002a008e2c",
        "min_likes": 1000,
        "timeout": 600
    }

    # è¯»å–å…³é”®è¯æ–‡ä»¶
    search_test_cases = []
    keyword_file = "å…³é”®è¯2.txt"  # æ–‡ä»¶è·¯å¾„å¯ä¿®æ”¹

    try:
        with open(keyword_file, "r", encoding="utf-8") as f:
            for line in f:
                # æ¸…æ´—å’ŒéªŒè¯å…³é”®è¯
                keyword = line.strip()
                if keyword:  # å¿½ç•¥ç©ºè¡Œ
                    search_test_cases.append({
                        "query": keyword,
                        "require_num": 50,
                        "min_likes": 200,
                        "note_type": 0,
                        "desc": f"å…³é”®è¯: {keyword}"
                    })
        print(f"æˆåŠŸåŠ è½½ {len(search_test_cases)} ä¸ªå…³é”®è¯")
    except Exception as e:
        print(f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
        exit()

    # æ‰§è¡Œæµ‹è¯•å¥—ä»¶
    print("\n" + "=" * 50)
    # test_user_crawler_with_status(**user_test_params)  # å¯é€‰ç”¨æˆ·æµ‹è¯•

    import random
    import time

    for index, case in enumerate(search_test_cases, 1):
        print(f"\n{'=' * 50}\næ­£åœ¨å¤„ç†ç¬¬ {index}/{len(search_test_cases)} ä¸ªå…³é”®è¯: {case['query']}")

        # æ‰§è¡Œæœç´¢æµ‹è¯•
        test_search_with_status(
            query=case["query"],
            require_num=case["require_num"],
            min_likes=case["min_likes"],
            note_type=case["note_type"]
        )

        # éšæœºç­‰å¾…
        # if index != len(search_test_cases):  # æœ€åä¸€ä¸ªä¸éœ€è¦ç­‰å¾…
        #     wait_time = random.randint(60, 80)  # 1-3åˆ†é’Ÿ
        #     print(f"\nğŸ•’ ä»»åŠ¡ {index} å®Œæˆï¼Œå¼€å§‹ä¼‘æ¯ {wait_time} ç§’...")
        #     time.sleep(wait_time)